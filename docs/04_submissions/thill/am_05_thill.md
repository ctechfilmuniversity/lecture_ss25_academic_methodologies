```
---
layout: default
title: Homework
nav_exclude: true
---
```

# 05.01 Related work

---

**These papers seem to having been peer-reviewed, presented at Conferences aswell as having been cited several times:**

1.    - **Jin et al. (2022) – [Logical Fallacy Detection - ACL Anthology](https://aclanthology.org/2022.findings-emnlp.532/) (Findings of EMNLP 2022)**  
        This paper presents one of the first comprehensive approaches to logical fallacy detection using neural networks, introducing a dataset and a multi-task learning framework. It is relevant to my work as it lays the groundwork for automated fallacy classification and highlights the challenges posed by contextual ambiguity and overlapping categories, which my study seeks to address through reasoning-aware prompting strategies.

2.    - **Wei et al. (2022) – [ Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/abs/2201.11903) (NeurIPS 2022)**  
        This paper introduces chain-of-thought (CoT) prompting as a method to improve the reasoning abilities of large language models across a range of complex tasks. It is highly relevant to my research, as I aim to apply CoT prompting to the specific domain of fallacy classification, with the hypothesis that intermediate reasoning steps will enhance both accuracy and interpretability.
   
3.    - **Anonymous et al. (2024) – [When LLMs Meet Cunning Texts: A Fallacy Understanding Benchmark for Large Language Models](https://arxiv.org/abs/2402.11100) (NeurIPS D&B Workshop 2024)** 
        This workshop paper proposes a new benchmark, FLUB, designed to evaluate the ability of large language models to understand and classify a diverse set of logical fallacies. It is directly relevant to my project as it provides recent empirical insights into model limitations and serves as a comparative reference point for assessing the effectiveness of CoT-based approaches.

---


**These papers make also a good impression, but I need to double-check them:**

---

[An Entity-Aware Approach to Logical Fallacy Detection in Kremlin Social Media Content | Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining](https://dl.acm.org/doi/10.1145/3625007.3627988)

---

**Wei, J., Wang, X., Schuurmans, D., Bosma, M., Zhao, D., Guu, K., & Le, Q. (2022). "Chain-of-Thought Prompting Elicits Reasoning in Large Language Models." In *Advances in Neural Information Processing Systems (NeurIPS 2022).*

[Chain-of-thought prompting elicits reasoning in large language models | Proceedings of the 36th International Conference on Neural Information Processing Systems](https://dl.acm.org/doi/10.5555/3600270.3602070)

---

[FALCON: A multi-label graph-based dataset for fallacy classification in the COVID-19 infodemic | Proceedings of the 40th ACM/SIGAPP Symposium on Applied Computing](https://dl.acm.org/doi/10.1145/3672608.3707913)

---

Habernal, I., Wachsmuth, H., Gurevych, I., & Stein, B. (2018). "Before Name-Calling: Dynamics and Triggers of Ad Hominem Fallacies in Web Argumentation." 
In *Proceedings of NAACL-HLT* (pp. 386–396).

---

Schaar, R. van der, & Popat, K. et al. (2023). "MAFALDA: A Benchmark for Fallacy Detection in Natural Language Argumentation." In *Findings of EMNLP 2023*.

[[2311.09761] MAFALDA: A Benchmark and Comprehensive Study of Fallacy Detection and Classification](https://arxiv.org/abs/2311.09761)

---

**I still need to check if these papers are at all relevant or serious enough to be considered.**

Habernal, I., Wachsmuth, H., Gurevych, I., & Stein, B. (2018). "The Argument Reasoning Comprehension Task: Identification and Reconstruction of Implicit Warrants." In *Proceedings of NAACL-HLT 2018*.

https://aclanthology.org/N18-1175/

---

[[2202.13758] Logical Fallacy Detection](https://arxiv.org/abs/2202.13758)

---

[[2210.03493] Automatic Chain of Thought Prompting in Large Language Models](https://arxiv.org/abs/2210.03493)

---

[[2503.23363] Large Language Models Are Better Logical Fallacy Reasoners with Counterargument, Explanation, and Goal-Aware Prompt Formulation](https://arxiv.org/abs/2503.23363)

---

[[2502.13125] RuozhiBench: Evaluating LLMs with Logical Fallacies and Misleading Premises](https://arxiv.org/abs/2502.13125)

---
