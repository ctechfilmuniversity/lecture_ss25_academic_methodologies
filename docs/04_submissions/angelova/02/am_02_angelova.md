---
layout: default
title: Homework
nav_exclude: true
---

**Academic Methodologies**
  
Prof. Dr. Lena Gieseke \| l.gieseke@filmuniversitaet.de \| Film University Babelsberg KONRAD WOLF
Alexander Walmsley \| a.walmsley@filmuniversitaet.de \| Film University Babelsberg KONRAD WOLF


## Session 01 - Introduction

* [Your Paper](#your-paper)
    * [Task 02.01 - Question Selection](#task-0201---question-selection)

## Your Paper

### Task 02.01 - Question Selection

- Exploring audio features extracted from bird songs
- Audio-visual generative systems from bird songs
- Mapping bird songs audio features to abstract visuals (using algorithms)?

My initial interest focuses on exploring what audio features could be extracted from birdsongs and how these could be mapped to visuals. This mapping could be a new sort of algorithm (most ambitious idea) or it could mean using the extracted audio features and feeding them as parameters to some morphogenesis algorithms (like Differential growth, Physarum, Boids, L-system, etc.).

If I would try to extract a more of a general topic from these questions, it would be something in the direction of:
- could we find some new, interesting relationships between audio and visual
- how could we map audio features to visual parameters in a new ways
- if and how audio features could change materials, geometries, etc
- what if audio features are used as input parameters for G-Buffers and explore possible modulations
- audio features and shaders - can I reinterpret audio features as meaningful inputs to the rendering pipeline, especially G-buffers and shaders, to create new audiovisual languages

I believe, that I could start from the more general idea - consider just audio and not specifically birdsongs, and depending on how the research goes, potentially narrow it down to specifically birdsongs.

---
