---
layout: default
title: Homework
nav_exclude: true
---

**Academic Methodologies**

# Session 05 - Qualitative Research

<!-- Reading the scripts and preparing questions should take < 2h. If you need longer, please let me know next class.

- [Session 05 - Qualitative Research](#session-05---qualitative-research)
- [Qualitative Research and Analysis (optional)](#qualitative-research-and-analysis-optional)
- [Your Paper](#your-paper)
  - [Task 05.01 - Related Work](#task-0501---related-work)
-->

## Task 05.01 - Related Work

<!--Collect related work for your paper. List _at least_ three, ideally academic, publications that you are planning to reference in your paper. Describe briefly, how the publications are related and relevant.

In case you are doing a literature review or survey list both, papers you are reviewing **and** some related work to your overall approach.-->

### 1. Measuring perceived empathy in dialogue systems

_Concannon, S., Tomalin, M. Measuring perceived empathy in dialogue systems. AI & Soc 39, 2233–2247 (2024)._ https://doi.org/10.1007/s00146-023-01715-z

The paper looks at how we can tell if in dialogue systems (DS) like Alexa or ChatGPT etc seem empathetic. Right now, there's no good, consistent way to measure this "empathetic" behavior. Different researchers use different tools and ideas, which makes it hard to compare systems. So, the authors created a new tool called the Empathy Scale for Human–Computer Communication (ESHCC). It's based on a tool used to rate empathy in therapists, but it was changed to work for AI conversations.
The goal is to help researchers fairly measure how empathetic an AI sounds when talking to people—so we can better design and compare these systems in the future.<br>

**Usage in Paper:** This could be great to see how they came up with the framework, look how they implement it.

### 2. Is ChatGPT More Empathetic than Humans?

_Is ChatGPT More Empathetic than Humans? (n.d.). Retrieved June 1, 2025, from_ https://arxiv.org/html/2403.05572v1

This paper critically evaluates the emotional simulation abilities of large language models (LLMs), including GPT variants. It identifies the strengths and shortcomings of current LLMs in reproducing human-like emotional responses.<br>

**Usage in Paper:** Helps define the current state of LLMs’ emotional capacities and contextualizes the necessity of new testing frameworks.

### 3. Simulating Emotions With an Integrated Computational Model of Appraisal and Reinforcement Learning

_Zhang, J. E., Hilpert, B., Broekens, J., & Jokinen, J. P. P. (2024). Simulating Emotions With an Integrated Computational Model of Appraisal and Reinforcement Learning. Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems, 1–12._ https://doi.org/10.1145/3613904.3641908

This paper analyses by comparing human and ChatGPT-4 responses to certain contexts. Here, a great focus lies on empathy and how emotional believable the answers are.

---

## Other papers I found interesting

### X. From Eliza to XiaoIce: Challenges and Opportunities with Social Chatbots

_Shum, H.-Y., He, X., & Li, D. (2018). From Eliza to XiaoIce: Challenges and Opportunities with Social Chatbots (No. arXiv:1801.01957). arXiv._ https://doi.org/10.48550/arXiv.1801.01957
https://arxiv.org/abs/1801.01957

### X. EmotionQueen: A Benchmark for Evaluating Empathy of Large Language Models

_Chen, Y., Wang, H., Yan, S., Liu, S., Li, Y., Zhao, Y., & Xiao, Y. (2024). EmotionQueen: A Benchmark for Evaluating Empathy of Large Language Models (No. arXiv:2409.13359). arXiv._ https://doi.org/10.48550/arXiv.2409.13359

### X. Empathy in AI: Developing a Sentiment-Sensitive Chatbot through Advanced Natural Language Processing

_Abuhmida, M., Islam, M. J., & Booth, W. (2024). Empathy in AI: Developing a Sentiment-Sensitive Chatbot through Advanced Natural Language Processing._ https://doi.org/10.30534/IJATCSE/2024/071332024
